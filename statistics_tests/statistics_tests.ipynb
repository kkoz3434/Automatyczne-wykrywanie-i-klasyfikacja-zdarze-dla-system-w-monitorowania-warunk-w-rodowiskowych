{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-25T17:02:33.256099871Z",
     "start_time": "2024-04-25T17:02:32.489437160Z"
    }
   },
   "outputs": [],
   "source": [
    "from common.data_frame_columns import TIMESTAMP\n",
    "from common.data_frame_columns import PM10, PM2_5, PM1\n",
    "from common.date_time_helper import convert_to_datetime\n",
    "from common.endpoints_urls import endpoints_config\n",
    "from data_management.data_crawler import DataManager\n",
    "from data_management.labeled_data_generator import LabeledDataGenerator, DataLabel"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading station data: Gronie  https://datahub.ki.agh.edu.pl/api/endpoints/70/data/\n",
      "    # Minimal data: 2022-07-13 23:38:02+00:00\n",
      "    # Maximal data: 2024-04-25 12:36:38+00:00\n",
      "Loading station data: Urząd Gminy  https://datahub.ki.agh.edu.pl/api/endpoints/71/data/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/kkoz34/HDD_kkoz34/Magisterka/Magisterka/data_management/data_crawler.py:93: DtypeWarning: Columns (44,49) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filename)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    # Minimal data: 2021-10-07 18:51:17+00:00\n",
      "    # Maximal data: 2024-04-25 12:43:51+00:00\n",
      "Loading station data: Młynne  https://datahub.ki.agh.edu.pl/api/endpoints/72/data/\n",
      "    # Minimal data: 2021-10-07 19:17:59+00:00\n",
      "    # Maximal data: 2024-04-25 12:33:14+00:00\n",
      "Loading station data: Sucharskiego  https://datahub.ki.agh.edu.pl/api/endpoints/73/data/\n",
      "    # Minimal data: 2021-10-07 19:41:43+00:00\n",
      "    # Maximal data: 2024-04-25 12:36:38+00:00\n",
      "Loading station data: Twardowskiego  https://datahub.ki.agh.edu.pl/api/endpoints/74/data/\n",
      "    # Minimal data: 2021-10-07 20:59:56+00:00\n",
      "    # Maximal data: 2024-04-25 12:38:24+00:00\n",
      "Loading station data: Konopnickiej  https://datahub.ki.agh.edu.pl/api/endpoints/75/data/\n",
      "    # Minimal data: 2021-10-07 21:07:07+00:00\n",
      "    # Maximal data: 2024-04-25 12:38:42+00:00\n",
      "Finished loading data \n",
      " \n",
      "Daily datas: 85\n",
      "Generated anomalies: 39\n",
      "    NOISE: 8\n",
      "    RANDOM_ZEROS: 11\n",
      "    NORMAL: 46\n",
      "    SCALED: 7\n",
      "    EXTINCTION: 7\n",
      "    ZEROS_IN_RANGE: 6\n"
     ]
    }
   ],
   "source": [
    "date_strings = ['01.01.2021 00:00', '28.02.2024 23:59']\n",
    "test_dates_string = ['01.02.2024 00:00', '25.04.2024 23:59']\n",
    "\n",
    "training_dates = [convert_to_datetime(date_strings[0]), convert_to_datetime(date_strings[1])]\n",
    "test_dates = [convert_to_datetime(test_dates_string[0]), convert_to_datetime(test_dates_string[1])]\n",
    "\n",
    "datas = DataManager(True).get_all_endpoints_data(endpoints_config, update=False)\n",
    "\n",
    "column = PM10\n",
    "L = LabeledDataGenerator(column)\n",
    "\n",
    "test_data = L.generate_labeled_data(datas[:1], test_dates[0], test_dates[1], 50)\n",
    "# single_data = L.generate_labeled_data(datas[:1], training_dates[0], training_dates[1], 40)\n",
    "# multi_data = L.generate_labeled_data(datas, training_dates[0], training_dates[1], 40)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-25T17:02:38.936091109Z",
     "start_time": "2024-04-25T17:02:33.297429298Z"
    }
   },
   "id": "970ba333be63cd7",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAD sensor level:\n",
      "    [Threshold: 1.0] Anomaly: 39/39 (1.0) | Normal 0.0 | 45.88%\n",
      "    [Threshold: 1.5] Anomaly: 31/39 (0.79) | Normal 4.35 | 38.82%\n",
      "    [Threshold: 2] Anomaly: 27/39 (0.69) | Normal 13.04 | 38.82%\n",
      "    [Threshold: 3] Anomaly: 19/39 (0.49) | Normal 30.43 | 38.82%\n",
      "    [Threshold: 4] Anomaly: 15/39 (0.38) | Normal 52.17 | 45.88%\n",
      "    [Threshold: 5] Anomaly: 13/39 (0.33) | Normal 71.74 | 54.12%\n",
      "    [Threshold: 6] Anomaly: 11/39 (0.28) | Normal 78.26 | 55.29%\n",
      "    [Threshold: 7] Anomaly: 9/39 (0.23) | Normal 84.78 | 56.47%\n",
      "    [Threshold: 8] Anomaly: 8/39 (0.21) | Normal 89.13 | 57.65%\n",
      "    [Threshold: 9] Anomaly: 8/39 (0.21) | Normal 93.48 | 60.0%\n",
      "    [Threshold: 10] Anomaly: 8/39 (0.21) | Normal 93.48 | 60.0%\n",
      "AVG sensor level:\n",
      "    [Threshold: 1.0] Anomaly: 39/39 (1.0) | Normal 0.0 | 45.88%\n",
      "    [Threshold: 1.5] Anomaly: 37/39 (0.95) | Normal 6.52 | 47.06%\n",
      "    [Threshold: 2] Anomaly: 16/39 (0.41) | Normal 39.13 | 40.0%\n",
      "    [Threshold: 3] Anomaly: 6/39 (0.15) | Normal 100.0 | 61.18%\n",
      "    [Threshold: 4] Anomaly: 6/39 (0.15) | Normal 100.0 | 61.18%\n",
      "    [Threshold: 5] Anomaly: 6/39 (0.15) | Normal 100.0 | 61.18%\n",
      "    [Threshold: 6] Anomaly: 6/39 (0.15) | Normal 100.0 | 61.18%\n",
      "    [Threshold: 7] Anomaly: 6/39 (0.15) | Normal 100.0 | 61.18%\n",
      "    [Threshold: 8] Anomaly: 6/39 (0.15) | Normal 100.0 | 61.18%\n",
      "    [Threshold: 9] Anomaly: 6/39 (0.15) | Normal 100.0 | 61.18%\n",
      "    [Threshold: 10] Anomaly: 6/39 (0.15) | Normal 100.0 | 61.18%\n",
      "MAD network level:\n",
      "    [Threshold: 1.0] Anomaly: 36/39 (0.92) | Normal 0.0 | 42.35%\n",
      "    [Threshold: 1.5] Anomaly: 29/39 (0.74) | Normal 10.87 | 40.0%\n",
      "    [Threshold: 2] Anomaly: 26/39 (0.67) | Normal 21.74 | 42.35%\n",
      "    [Threshold: 3] Anomaly: 22/39 (0.56) | Normal 41.3 | 48.24%\n",
      "    [Threshold: 4] Anomaly: 20/39 (0.51) | Normal 56.52 | 54.12%\n",
      "    [Threshold: 5] Anomaly: 17/39 (0.44) | Normal 65.22 | 55.29%\n",
      "    [Threshold: 6] Anomaly: 17/39 (0.44) | Normal 73.91 | 60.0%\n",
      "    [Threshold: 7] Anomaly: 15/39 (0.38) | Normal 78.26 | 60.0%\n",
      "    [Threshold: 8] Anomaly: 14/39 (0.36) | Normal 84.78 | 62.35%\n",
      "    [Threshold: 9] Anomaly: 12/39 (0.31) | Normal 84.78 | 60.0%\n",
      "    [Threshold: 10] Anomaly: 11/39 (0.28) | Normal 89.13 | 61.18%\n",
      "AVG network level:\n",
      "    [Threshold: 1.0] Anomaly: 33/39 (0.85) | Normal 0.0 | 38.82%\n",
      "    [Threshold: 1.5] Anomaly: 27/39 (0.69) | Normal 28.26 | 47.06%\n",
      "    [Threshold: 2] Anomaly: 19/39 (0.49) | Normal 45.65 | 47.06%\n",
      "    [Threshold: 3] Anomaly: 17/39 (0.44) | Normal 91.3 | 69.41%\n",
      "    [Threshold: 4] Anomaly: 15/39 (0.38) | Normal 100.0 | 71.76%\n",
      "    [Threshold: 5] Anomaly: 11/39 (0.28) | Normal 100.0 | 67.06%\n",
      "    [Threshold: 6] Anomaly: 10/39 (0.26) | Normal 100.0 | 65.88%\n",
      "    [Threshold: 7] Anomaly: 9/39 (0.23) | Normal 100.0 | 64.71%\n",
      "    [Threshold: 8] Anomaly: 8/39 (0.21) | Normal 100.0 | 63.53%\n",
      "    [Threshold: 9] Anomaly: 7/39 (0.18) | Normal 100.0 | 62.35%\n",
      "    [Threshold: 10] Anomaly: 7/39 (0.18) | Normal 100.0 | 62.35%\n"
     ]
    }
   ],
   "source": [
    "from detectors.z_score_detector import ZScoreDetector\n",
    "import pandas as pd\n",
    "\n",
    "column = PM10\n",
    "thresholds = [1.0, 1.5, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "#single sensor detection\n",
    "zscore = ZScoreDetector()\n",
    "print(f\"MAD sensor level:\")\n",
    "for threshold in thresholds:\n",
    "    data_length = 0\n",
    "    correct_anomaly = 0\n",
    "    correct_normal = 0\n",
    "    anomaly = 0\n",
    "    normal = 0\n",
    "    for dataframe, label in test_data:\n",
    "        if not dataframe.empty:\n",
    "            data_length += 1\n",
    "            start_time = dataframe[TIMESTAMP].min()\n",
    "            end_time = dataframe[TIMESTAMP].max()\n",
    "            outliers = ZScoreDetector().detect_by_mad(dataframe, column, start_time, end_time, threshold)\n",
    "            if label.value > 0:\n",
    "                anomaly += 1\n",
    "                if (len(outliers) > 5):\n",
    "                    correct_anomaly += 1\n",
    "            if label.value == 0:\n",
    "                normal += 1\n",
    "                if (len(outliers) < 5):\n",
    "                    correct_normal += 1\n",
    "\n",
    "    print(\n",
    "        f'    [Threshold: {threshold}] Anomaly: {correct_anomaly}/{anomaly} ({round(correct_anomaly / anomaly, 2)}) | Normal {round(correct_normal / normal * 100, 2)} | {round((correct_anomaly + correct_normal) / (anomaly + normal) * 100, 2)}%')\n",
    "\n",
    "print(f\"AVG sensor level:\")\n",
    "for threshold in thresholds:\n",
    "    data_length = 0\n",
    "    correct_anomaly = 0\n",
    "    correct_normal = 0\n",
    "    anomaly = 0\n",
    "    normal = 0\n",
    "    for dataframe, label in test_data:\n",
    "        if not dataframe.empty:\n",
    "            data_length += 1\n",
    "            start_time = dataframe[TIMESTAMP].min()\n",
    "            end_time = dataframe[TIMESTAMP].max()\n",
    "            outliers = ZScoreDetector().detect_by_avg(dataframe, column, start_time, end_time, threshold)\n",
    "            if label.value > 0:\n",
    "                anomaly += 1\n",
    "                if (len(outliers) > 5):\n",
    "                    correct_anomaly += 1\n",
    "            if label.value == 0:\n",
    "                normal += 1\n",
    "                if (len(outliers) < 5):\n",
    "                    correct_normal += 1\n",
    "\n",
    "    print(\n",
    "        f'    [Threshold: {threshold}] Anomaly: {correct_anomaly}/{anomaly} ({round(correct_anomaly / anomaly, 2)}) | Normal {round(correct_normal / normal * 100, 2)} | {round((correct_anomaly + correct_normal) / (anomaly + normal) * 100, 2)}%')\n",
    "\n",
    "print(f\"MAD network level:\")\n",
    "for threshold in thresholds:\n",
    "    data_length = 0\n",
    "    correct_anomaly = 0\n",
    "    correct_normal = 0\n",
    "    anomaly = 0\n",
    "    normal = 0\n",
    "    for dataframe, label in test_data:\n",
    "        if not dataframe.empty:\n",
    "            data_length += 1\n",
    "            start_time = dataframe[TIMESTAMP].min()\n",
    "            end_time = dataframe[TIMESTAMP].max()\n",
    "            outliers = ZScoreDetector().detect_by_mad_network_level(datas, dataframe, column, start_time, end_time,\n",
    "                                                                    threshold)\n",
    "            if label.value > 0:\n",
    "                anomaly += 1\n",
    "                if (len(outliers) > 5):\n",
    "                    correct_anomaly += 1\n",
    "            if label.value == 0:\n",
    "                normal += 1\n",
    "                if (len(outliers) < 5):\n",
    "                    correct_normal += 1\n",
    "\n",
    "    print(\n",
    "        f'    [Threshold: {threshold}] Anomaly: {correct_anomaly}/{anomaly} ({round(correct_anomaly / anomaly, 2)}) | Normal {round(correct_normal / normal * 100, 2)} | {round((correct_anomaly + correct_normal) / (anomaly + normal) * 100, 2)}%')\n",
    "\n",
    "print(f\"AVG network level:\")\n",
    "for threshold in thresholds:\n",
    "    data_length = 0\n",
    "    correct_anomaly = 0\n",
    "    correct_normal = 0\n",
    "    anomaly = 0\n",
    "    normal = 0\n",
    "    for dataframe, label in test_data:\n",
    "        if not dataframe.empty:\n",
    "            data_length += 1\n",
    "            start_time = dataframe[TIMESTAMP].min()\n",
    "            end_time = dataframe[TIMESTAMP].max()\n",
    "            outliers = ZScoreDetector().detect_by_avg_network_level(datas, dataframe, column, start_time, end_time,\n",
    "                                                                    threshold)\n",
    "            if label.value > 0:\n",
    "                anomaly += 1\n",
    "                if (len(outliers) > 5):\n",
    "                    correct_anomaly += 1\n",
    "            if label.value == 0:\n",
    "                normal += 1\n",
    "                if (len(outliers) < 5):\n",
    "                    correct_normal += 1\n",
    "\n",
    "    print(\n",
    "        f'    [Threshold: {threshold}] Anomaly: {correct_anomaly}/{anomaly} ({round(correct_anomaly / anomaly, 2)}) | Normal {round(correct_normal / normal * 100, 2)} | {round((correct_anomaly + correct_normal) / (anomaly + normal) * 100, 2)}%')\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-25T17:02:56.893641876Z",
     "start_time": "2024-04-25T17:02:38.940452796Z"
    }
   },
   "id": "b217078dae9a1d4e",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERIODIC_MAD sensor level:\n",
      "    [Threshold: 1.0] Anomaly: 39/39 (1.0) | Normal 0.0 | 45.88%\n",
      "    [Threshold: 1.5] Anomaly: 33/39 (0.85) | Normal 13.04 | 45.88%\n",
      "    [Threshold: 2] Anomaly: 25/39 (0.64) | Normal 26.09 | 43.53%\n",
      "    [Threshold: 3] Anomaly: 19/39 (0.49) | Normal 60.87 | 55.29%\n",
      "    [Threshold: 4] Anomaly: 16/39 (0.41) | Normal 78.26 | 61.18%\n",
      "    [Threshold: 5] Anomaly: 15/39 (0.38) | Normal 89.13 | 65.88%\n",
      "    [Threshold: 6] Anomaly: 14/39 (0.36) | Normal 93.48 | 67.06%\n",
      "    [Threshold: 7] Anomaly: 13/39 (0.33) | Normal 93.48 | 65.88%\n",
      "    [Threshold: 8] Anomaly: 13/39 (0.33) | Normal 97.83 | 68.24%\n",
      "    [Threshold: 9] Anomaly: 13/39 (0.33) | Normal 100.0 | 69.41%\n",
      "    [Threshold: 10] Anomaly: 12/39 (0.31) | Normal 100.0 | 68.24%\n",
      "PERIODIC_AVG sensor level:\n",
      "    [Threshold: 1.0] Anomaly: 39/39 (1.0) | Normal 0.0 | 45.88%\n",
      "    [Threshold: 1.5] Anomaly: 30/39 (0.77) | Normal 23.91 | 48.24%\n",
      "    [Threshold: 2] Anomaly: 20/39 (0.51) | Normal 63.04 | 57.65%\n",
      "    [Threshold: 3] Anomaly: 9/39 (0.23) | Normal 100.0 | 64.71%\n",
      "    [Threshold: 4] Anomaly: 0/39 (0.0) | Normal 100.0 | 54.12%\n",
      "    [Threshold: 5] Anomaly: 0/39 (0.0) | Normal 100.0 | 54.12%\n",
      "    [Threshold: 6] Anomaly: 0/39 (0.0) | Normal 100.0 | 54.12%\n",
      "    [Threshold: 7] Anomaly: 0/39 (0.0) | Normal 100.0 | 54.12%\n",
      "    [Threshold: 8] Anomaly: 0/39 (0.0) | Normal 100.0 | 54.12%\n",
      "    [Threshold: 9] Anomaly: 0/39 (0.0) | Normal 100.0 | 54.12%\n",
      "    [Threshold: 10] Anomaly: 0/39 (0.0) | Normal 100.0 | 54.12%\n",
      "PERIODIC_MAD network level:\n",
      "    [Threshold: 1.0] Anomaly: 39/39 (1.0) | Normal 0.0 | 45.88%\n",
      "    [Threshold: 1.5] Anomaly: 32/39 (0.82) | Normal 21.74 | 49.41%\n",
      "    [Threshold: 2] Anomaly: 25/39 (0.64) | Normal 32.61 | 47.06%\n",
      "    [Threshold: 3] Anomaly: 16/39 (0.41) | Normal 54.35 | 48.24%\n",
      "    [Threshold: 4] Anomaly: 14/39 (0.36) | Normal 69.57 | 54.12%\n",
      "    [Threshold: 5] Anomaly: 14/39 (0.36) | Normal 86.96 | 63.53%\n",
      "    [Threshold: 6] Anomaly: 13/39 (0.33) | Normal 91.3 | 64.71%\n",
      "    [Threshold: 7] Anomaly: 13/39 (0.33) | Normal 93.48 | 65.88%\n",
      "    [Threshold: 8] Anomaly: 12/39 (0.31) | Normal 95.65 | 65.88%\n",
      "    [Threshold: 9] Anomaly: 12/39 (0.31) | Normal 100.0 | 68.24%\n",
      "    [Threshold: 10] Anomaly: 11/39 (0.28) | Normal 100.0 | 67.06%\n",
      "PERIODIC_AVG network level:\n",
      "    [Threshold: 1.0] Anomaly: 38/39 (0.97) | Normal 0.0 | 44.71%\n",
      "    [Threshold: 1.5] Anomaly: 31/39 (0.79) | Normal 30.43 | 52.94%\n",
      "    [Threshold: 2] Anomaly: 19/39 (0.49) | Normal 63.04 | 56.47%\n",
      "    [Threshold: 3] Anomaly: 15/39 (0.38) | Normal 97.83 | 70.59%\n",
      "    [Threshold: 4] Anomaly: 14/39 (0.36) | Normal 97.83 | 69.41%\n",
      "    [Threshold: 5] Anomaly: 13/39 (0.33) | Normal 97.83 | 68.24%\n",
      "    [Threshold: 6] Anomaly: 10/39 (0.26) | Normal 100.0 | 65.88%\n",
      "    [Threshold: 7] Anomaly: 10/39 (0.26) | Normal 100.0 | 65.88%\n",
      "    [Threshold: 8] Anomaly: 10/39 (0.26) | Normal 100.0 | 65.88%\n",
      "    [Threshold: 9] Anomaly: 10/39 (0.26) | Normal 100.0 | 65.88%\n",
      "    [Threshold: 10] Anomaly: 10/39 (0.26) | Normal 100.0 | 65.88%\n"
     ]
    }
   ],
   "source": [
    "from detectors.pseudo_periodic import PseudoPeriodicDetector\n",
    "import pandas as pd\n",
    "\n",
    "column = PM10\n",
    "sensor_data = datas[0]\n",
    "thresholds = [1.0, 1.5, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "#single sensor detection\n",
    "\n",
    "print(f\"PERIODIC_MAD sensor level:\")\n",
    "for threshold in thresholds:\n",
    "    data_length = 0\n",
    "    correct_anomaly = 0\n",
    "    correct_normal = 0\n",
    "    anomaly = 0\n",
    "    normal = 0\n",
    "    for dataframe, label in test_data:\n",
    "        if not dataframe.empty:\n",
    "            data_length += 1\n",
    "            start_time = dataframe[TIMESTAMP].min()\n",
    "            end_time = dataframe[TIMESTAMP].max()\n",
    "            destroyed = sensor_data.copy()\n",
    "            destroyed.name = sensor_data.name\n",
    "            destroyed.update(dataframe)\n",
    "            outliers = PseudoPeriodicDetector().detect_by_periodic_mad(destroyed, column, start_time, end_time,\n",
    "                                                                       threshold=threshold)\n",
    "            if label.value > 0:\n",
    "                anomaly += 1\n",
    "                if (len(outliers) > 5):\n",
    "                    correct_anomaly += 1\n",
    "            if label.value == 0:\n",
    "                normal += 1\n",
    "                if (len(outliers) < 5):\n",
    "                    correct_normal += 1\n",
    "\n",
    "    print(\n",
    "        f'    [Threshold: {threshold}] Anomaly: {correct_anomaly}/{anomaly} ({round(correct_anomaly / anomaly, 2)}) | Normal {round(correct_normal / normal * 100, 2)} | {round((correct_anomaly + correct_normal) / data_length * 100, 2)}%')\n",
    "\n",
    "print(f\"PERIODIC_AVG sensor level:\")\n",
    "for threshold in thresholds:\n",
    "    data_length = 0\n",
    "    correct_anomaly = 0\n",
    "    correct_normal = 0\n",
    "    anomaly = 0\n",
    "    normal = 0\n",
    "    for dataframe, label in test_data:\n",
    "        if not dataframe.empty:\n",
    "            data_length += 1\n",
    "            start_time = dataframe[TIMESTAMP].min()\n",
    "            end_time = dataframe[TIMESTAMP].max()\n",
    "            destroyed = sensor_data.copy()\n",
    "            destroyed.name = sensor_data.name\n",
    "            destroyed.update(dataframe)\n",
    "            outliers = PseudoPeriodicDetector().detect_by_periodic_avg(destroyed, column, start_time, end_time,\n",
    "                                                                       threshold=threshold)\n",
    "            if label.value > 0:\n",
    "                anomaly += 1\n",
    "                if (len(outliers) > 5):\n",
    "                    correct_anomaly += 1\n",
    "            if label.value == 0:\n",
    "                normal += 1\n",
    "                if (len(outliers) < 5):\n",
    "                    correct_normal += 1\n",
    "\n",
    "    print(\n",
    "        f'    [Threshold: {threshold}] Anomaly: {correct_anomaly}/{anomaly} ({round(correct_anomaly / anomaly, 2)}) | Normal {round(correct_normal / normal * 100, 2)} | {round((correct_anomaly + correct_normal) / data_length * 100, 2)}%')\n",
    "\n",
    "print(f\"PERIODIC_MAD network level:\")\n",
    "for threshold in thresholds:\n",
    "    data_length = 0\n",
    "    correct_anomaly = 0\n",
    "    correct_normal = 0\n",
    "    anomaly = 0\n",
    "    normal = 0\n",
    "    for dataframe, label in test_data:\n",
    "        if not dataframe.empty:\n",
    "            data_length += 1\n",
    "            start_time = dataframe[TIMESTAMP].min()\n",
    "            end_time = dataframe[TIMESTAMP].max()\n",
    "            destroyed = sensor_data.copy()\n",
    "            destroyed.name = sensor_data.name\n",
    "            destroyed.update(dataframe)\n",
    "            outliers = PseudoPeriodicDetector().detect_by_periodic_mad_network_level(datas, destroyed, column,\n",
    "                                                                                     start_time, end_time,\n",
    "                                                                                     threshold=threshold)\n",
    "            if label.value > 0:\n",
    "                anomaly += 1\n",
    "                if (len(outliers) > 5):\n",
    "                    correct_anomaly += 1\n",
    "            if label.value == 0:\n",
    "                normal += 1\n",
    "                if (len(outliers) < 5):\n",
    "                    correct_normal += 1\n",
    "\n",
    "    print(\n",
    "        f'    [Threshold: {threshold}] Anomaly: {correct_anomaly}/{anomaly} ({round(correct_anomaly / anomaly, 2)}) | Normal {round(correct_normal / normal * 100, 2)} | {round((correct_anomaly + correct_normal) / data_length * 100, 2)}%')\n",
    "\n",
    "print(f\"PERIODIC_AVG network level:\")\n",
    "for threshold in thresholds:\n",
    "    data_length = 0\n",
    "    correct_anomaly = 0\n",
    "    correct_normal = 0\n",
    "    anomaly = 0\n",
    "    normal = 0\n",
    "    for dataframe, label in test_data:\n",
    "        if not dataframe.empty:\n",
    "            data_length += 1\n",
    "            start_time = dataframe[TIMESTAMP].min()\n",
    "            end_time = dataframe[TIMESTAMP].max()\n",
    "            destroyed = sensor_data.copy()\n",
    "            destroyed.name = sensor_data.name\n",
    "            destroyed.update(dataframe)\n",
    "            outliers = PseudoPeriodicDetector().detect_by_periodic_avg_network_level(datas,  destroyed, column,\n",
    "                                                                                     start_time, end_time,\n",
    "                                                                                     threshold=threshold)\n",
    "            if label.value > 0:\n",
    "                anomaly += 1\n",
    "                if (len(outliers) > 5):\n",
    "                    correct_anomaly += 1\n",
    "            if label.value == 0:\n",
    "                normal += 1\n",
    "                if (len(outliers) < 5):\n",
    "                    correct_normal += 1\n",
    "\n",
    "    print(\n",
    "        f'    [Threshold: {threshold}] Anomaly: {correct_anomaly}/{anomaly} ({round(correct_anomaly / anomaly, 2)}) | Normal {round(correct_normal / normal * 100, 2)} | {round((correct_anomaly + correct_normal) / data_length * 100, 2)}%')\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-25T17:15:44.829721086Z",
     "start_time": "2024-04-25T17:02:56.904905534Z"
    }
   },
   "id": "8696153840559eaa",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-25T17:15:44.830156700Z",
     "start_time": "2024-04-25T17:15:44.829619628Z"
    }
   },
   "id": "77d0fe37d74a403d",
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
